{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### greencar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "from pandas_gbq import to_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_list = [' ']\n",
    "columns = [\"zoneName\", \"address\", \"latitude\", \"longitude\",\"type\"]\n",
    "api_key = \"OniyFz9aRuv6SpCF+x2ytMHyEeMTJ9DXHyWdz+JL6RnGVrrEXR+aeKYZ0+4xah26a3Kuk0TTspLZ7MACxZObgg==\"\n",
    "url = 'http://apis.data.go.kr/1613000/CarSharingInfoService/getCarZoneListByName'\n",
    "\n",
    "df1_1 = pd.DataFrame()\n",
    "\n",
    "for address in address_list:\n",
    "    params ={'serviceKey' : api_key, 'pageNo' : '1', 'numOfRows' : '5000', '_type' : 'json', 'zoneName' : address }\n",
    "    response = requests.get(url, params=params)\n",
    "    result=json.loads(response.content.decode('utf-8'))\n",
    "\n",
    "    if \"response\" in result and \"body\" in result[\"response\"] and \"items\" in result[\"response\"][\"body\"] and \"item\" in result[\"response\"][\"body\"][\"items\"]:\n",
    "        item = result[\"response\"][\"body\"][\"items\"][\"item\"]\n",
    "        if type(item) == dict :\n",
    "            item = [item]\n",
    "            temp_df = pd.DataFrame(item)\n",
    "        elif type(item) == list :\n",
    "            temp_df = pd.DataFrame(item)\n",
    "\n",
    "        df1_1 = pd.concat([df1_1, temp_df], ignore_index=True)\n",
    "    else :\n",
    "        continue  \n",
    "df1_1 = df1_1[columns]\n",
    "df1_1 = df1_1[df1_1[\"type\"]==2]\n",
    "# 운행종료 제거\n",
    "df1_1_filtered = df1_1[~df1_1[\"zoneName\"].str.contains(r\"운영종료\", na=False)].drop_duplicates()\n",
    "\n",
    "#두 번째 데이터셋\n",
    "df1_2 = pd.read_csv(\"./전국렌터카업체정보표준데이터.csv\", encoding=\"euc-kr\")\n",
    "def choose_address(row):\n",
    "    # 둘 다 존재하면 도로명 주소 사용\n",
    "    if pd.notna(row[\"차고지도로명주소\"]) and pd.notna(row[\"차고지지번주소\"]):\n",
    "        return row[\"차고지지번주소\"]\n",
    "    # 하나만 존재하면 해당 주소 사용\n",
    "    elif pd.notna(row[\"차고지도로명주소\"]):\n",
    "        return row[\"차고지도로명주소\"]\n",
    "    elif pd.notna(row[\"차고지지번주소\"]):\n",
    "        return row[\"차고지지번주소\"]\n",
    "    # 둘 다 없으면 NaN\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# 각 행에 대해 choose_address 함수 적용\n",
    "df1_2[\"address\"] = df1_2.apply(choose_address, axis=1)\n",
    "\n",
    "columns = ['제공기관명', \"address\", '위도', '경도']\n",
    "df1_2_filtered = df1_2[df1_2[\"업체명\"].str.contains(r\"그린카\", na=False)]\n",
    "df1_2_filtered = df1_2_filtered[columns]\n",
    "df1_2_filtered.rename(columns={\"제공기관명\":\"zoneName\",\n",
    "                              \"위도\":\"latitude\",\n",
    "                              \"경도\":\"longitude\",\n",
    "                              }, inplace=True)\n",
    "\n",
    "df1_greencar = pd.concat([df1_1_filtered, df1_2_filtered], ignore_index=True)\n",
    "df1_greencar[\"latitude\"] = df1_greencar[\"latitude\"].round(3)\n",
    "df1_greencar[\"longitude\"] = df1_greencar[\"longitude\"].round(3)\n",
    "df1_greencar.drop(columns = [\"type\"], inplace=True)\n",
    "\n",
    "# 위도, 경도 기준으로 중복 제거\n",
    "df1_greencar = df1_greencar.drop_duplicates(subset=[\"latitude\", \"longitude\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### licenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_licenses = pd.read_excel(\"./운전면허소지자현황_지역별__20241208031332.xlsx\")\n",
    "df2_licenses = df2_licenses.iloc[-4:, 4:]\n",
    "# 1행부터 4행까지 합산 (숫자 데이터만)\n",
    "df2_licenses = df2_licenses.iloc[0:4, :].apply(pd.to_numeric, errors='coerce').sum(axis=0).reset_index()\n",
    "df2_licenses.columns = ['Region', 'license']\n",
    "\n",
    "# 경기남부와 경기북부 합산\n",
    "gyeonggi_sum = df2_licenses.loc[df2_licenses['Region'].isin(['경기남부', '경기북부']), 'license'].sum()\n",
    "# 새로운 경기 행 생성\n",
    "gyeonggi_row = pd.DataFrame({'Region': ['경기'], 'license': [gyeonggi_sum]})\n",
    "# 경기남부와 경기북부 제거 후 새로운 행 추가\n",
    "df2_licenses = pd.concat([df2_licenses[~df2_licenses['Region'].isin(['경기남부', '경기북부'])], gyeonggi_row], ignore_index=True)\n",
    "\n",
    "region_mapping = {\n",
    "    '서울': '서울특별시',\n",
    "    '세종': '세종특별자치시',\n",
    "    '부산': '부산광역시',\n",
    "    '대구': '대구광역시',\n",
    "    '인천': '인천광역시',\n",
    "    '광주': '광주광역시',\n",
    "    '대전': '대전광역시',\n",
    "    '울산': '울산광역시',\n",
    "    '경기': '경기도',\n",
    "    '강원': '강원도',\n",
    "    '경남': '경상남도',\n",
    "    '경북': '경상북도',\n",
    "    '전남': '전라남도',\n",
    "    '전북': '전라북도',\n",
    "    '충남': '충청남도',\n",
    "    '충북': '충청북도',\n",
    "    '제주': '제주특별자치도'\n",
    "}\n",
    "\n",
    "# Region 열 값 변경\n",
    "df2_licenses['Region'] = df2_licenses['Region'].replace(region_mapping)\n",
    "df2_licenses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### transports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_transport1 = pd.read_csv(\"./KC_496_LLR_PPLTEQP_2023.csv\")\n",
    "df3_transport1[\"longitude\"] = df3_transport1[\"LC_LO\"].round(3)\n",
    "df3_transport1[\"latitude\"] = df3_transport1[\"LC_LA\"].round(3)\n",
    "columns_transport = [\n",
    "           \"POI_NM\",\n",
    "           \"CTPRVN_NM\",\n",
    "           \"SIGNGU_NM\",\n",
    "           \"LEGALDONG_NM\",\n",
    "           \"LI_NM\",\n",
    "           \"longitude\",\n",
    "           \"latitude\",\n",
    "           ]\n",
    "df3_transport1 = df3_transport1[columns_transport]\n",
    "df3_transport1.fillna(0, inplace=True)\n",
    "names = [\"택시\", \"선착장\", \"역\", \"항\", \"여객\", \"유람선\", \"나루\", \"부두\", \"교\", \"댐\", \"다리\", \"광사\"]\n",
    "pattern = '|'.join(names)\n",
    "# 불필요 제거\n",
    "df3_transport = df3_transport1[~df3_transport1[\"POI_NM\"].str.contains(pattern, na=False)].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address(address):\n",
    "    # address 끝에 '-0'이 있으면 제거\n",
    "    if address.endswith(\"-0\"):\n",
    "        return address[:-2]\n",
    "    return address\n",
    "\n",
    "def get_coordinates_without_api(address):\n",
    "    try:\n",
    "        # OpenStreetMap Nominatim 검색 URL\n",
    "        base_url = \"https://nominatim.openstreetmap.org/search\"\n",
    "\n",
    "        # 파라미터 구성\n",
    "        params = {\n",
    "            \"q\": address,\n",
    "            \"format\": \"json\"\n",
    "        }\n",
    "\n",
    "        # 요청 URL 생성\n",
    "        url = f\"{base_url}?{urllib.parse.urlencode(params)}\"\n",
    "\n",
    "        # 요청 보내기\n",
    "        response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "        # 응답 JSON 파싱\n",
    "        if response.status_code == 200:\n",
    "            results = response.json()\n",
    "            if results:\n",
    "                latitude = results[0][\"lat\"]\n",
    "                longitude = results[0][\"lon\"]\n",
    "                return latitude, longitude\n",
    "            else:\n",
    "                print(\"주소를 찾을 수 없습니다.\")\n",
    "                return None, None\n",
    "        else:\n",
    "            print(f\"Error: HTTP {response.status_code}\")\n",
    "            return None, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 읽기\n",
    "df4_poi = pd.read_csv(\"./20241212192423_지역별 관광지 검색순위.csv\", encoding=\"euc-kr\")\n",
    "columns_poi = ['관광지명', '도로명주소', '중분류 카테고리', '소분류 카테고리','검색건수']\n",
    "\n",
    "df4_poi = df4_poi[df4_poi['소분류 카테고리'] != \"교통시설\"][columns_poi].sort_values(by=\"검색건수\", ascending=False)\n",
    "df4_poi = df4_poi.rename(columns={\n",
    "    '관광지명':'POI_NM',\n",
    "    '도로명주소':'address',\n",
    "    '중분류 카테고리':'middle category',\n",
    "    '소분류 카테고리':'small category',\n",
    "    '검색건수':'SCCNT_VALUE'\n",
    "})\n",
    "\n",
    "# clean_address 함수를 벡터화 연산으로 적용\n",
    "df4_poi['address'] = df4_poi['address'].apply(clean_address)\n",
    "\n",
    "# 위도와 경도를 저장할 컬럼 추가\n",
    "df4_poi[\"latitude\"] = 0\n",
    "df4_poi[\"longitude\"] = 0\n",
    "\n",
    "\n",
    "# 각 address에 대해 위도, 경도를 검색하고 삽입\n",
    "for index, row in df4_poi.iterrows():\n",
    "    latitude, longitude = get_coordinates_without_api(row[\"address\"])\n",
    "    if latitude and longitude:\n",
    "        df4_poi.at[index, \"latitude\"] = latitude\n",
    "        df4_poi.at[index, \"longitude\"] = longitude\n",
    "\n",
    "df4_poi = df4_poi[~((df4_poi['latitude'] == 0) & (df4_poi['longitude'] == 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_poi = df4_poi[~((df4_poi['latitude'] == 0) | (df4_poi['longitude'] == 0))]\n",
    "df4_poi = df4_poi.dropna(subset=['longitude', 'latitude'])  # 결측값 제거\n",
    "df4_poi[\"longitude\"] = pd.to_numeric(df4_poi[\"longitude\"], errors=\"coerce\")\n",
    "df4_poi[\"latitude\"] = pd.to_numeric(df4_poi[\"latitude\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_total_mapping = {\n",
    "    '서울특별시': ['서울']+sorted([\n",
    "                        \"종로구\", \"중구\", \"용산구\", \"성동구\", \"광진구\", \"동대문구\", \"중랑구\", \n",
    "                        \"성북구\", \"강북구\", \"도봉구\", \"노원구\", \"은평구\", \"서대문구\", \"마포구\", \n",
    "                        \"양천구\", \"강서구\", \"구로구\", \"금천구\", \"영등포구\", \"동작구\", \"관악구\", \n",
    "                        \"서초구\", \"강남구\", \"송파구\", \"강동구\"\n",
    "                        ], reverse=True),\n",
    "    '세종특별자치시':[\"세종\"],\n",
    "    '부산광역시': [\"부산\"],\n",
    "    '대구광역시': ['대구'],\n",
    "    '인천광역시': ['인천'],\n",
    "    '광주광역시': [\"광주광역시\"],\n",
    "    '대전광역시': [\"대전\"],\n",
    "    '울산광역시': [\"울산\"],\n",
    "    '광주광역시': [\"광주\"],\n",
    "    '경기도': ['경기', '수원시', '고양시', '화성시', '성남시', '용인시', '부천시', '안양시', '시흥시', '기타 경기도 지역'],\n",
    "    '강원도': ['강원', '춘천시', '강릉시', '원주시', '기타 강원도 지역'],\n",
    "    '경상남도': ['경남', '창원시', '김해시', '기타 경상남도 지역'],\n",
    "    '경상북도': ['경북', '포항시', '경주시', '기타 경상북도 지역'],\n",
    "    '전라남도': ['전남', '여수시', '순천시', '목포시', '기타 전라남도 지역'],\n",
    "    '전라북도': ['전북', '전주시', '군산시', '익산시', '기타 전라북도 지역'],\n",
    "    '충청남도': ['충남', '천안시', '아산시', '기타 충청남도 지역'],\n",
    "    '충청북도': ['충북', '청주시', '충주시', '기타 충청북도 지역'],\n",
    "    '제주특별자치도': ['제주', '서귀포']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매핑을 정규식으로 처리\n",
    "for region, names in region_total_mapping.items():\n",
    "    pattern = '|'.join([region]+names)  # 지역 리스트를 OR로 결합\n",
    "    df1_greencar[region] = df1_greencar[\"address\"].str.contains(pattern, case=False, na=False).astype(int)\n",
    "\n",
    "# 결측값 처리 (필요한 경우)\n",
    "df1_greencar[\"address\"].fillna(\"\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구별 처리\n",
    "for i in region_total_mapping[\"서울특별시\"][1:]:\n",
    "    valid_columns = [col for col in region_total_mapping[\"서울특별시\"][1:] if col in df1_greencar.columns]\n",
    "    mask = (df1_greencar[\"서울특별시\"]==1) & (df1_greencar[valid_columns].sum(axis=1) == 0)\n",
    "    df1_greencar.loc[mask, i] = df1_greencar.loc[mask, \"address\"].str.contains(rf\"{i}\").astype(int)\n",
    "    df1_greencar[i].fillna(0, inplace=True)\n",
    "    df1_greencar[i] = df1_greencar[i].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기타{region}지역을 제외한 도별 주요 도시 처리\n",
    "for region in list(region_total_mapping.keys())[8:-1]: #서울, 광역시, 제주 제외\n",
    "    mask = (df1_greencar[f\"{region}\"]==1)\n",
    "    for i in region_total_mapping[f\"{region}\"][1:-1]: #지역(대단위)와 기타{region}지역 제외\n",
    "        valid_columns = [col for col in region_total_mapping[f\"{region}\"][1:-1] if col in df1_greencar.columns]\n",
    "        mask = (df1_greencar[f\"{region}\"]==1) & (df1_greencar[valid_columns].sum(axis=1) == 0)\n",
    "        j = i[:-1]\n",
    "        df1_greencar.loc[mask, i] = df1_greencar.loc[mask, \"address\"].str.contains(rf\"{j}\").astype(int)\n",
    "        # 나머지는 경기 여부를 0으로 설정\n",
    "        df1_greencar[i].fillna(0, inplace=True)\n",
    "        df1_greencar[i] = df1_greencar[i].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도별 주요 도시를 제외한 기타 지역 처리\n",
    "for region in list(region_total_mapping.keys())[8:-1]: #서울, 광역시, 제주 제외 \n",
    "    city_list = region_total_mapping[f\"{region}\"][1:-1]\n",
    "\n",
    "    #조건 설정\n",
    "    mask = (df1_greencar[f\"{region}\"]==1)&(df1_greencar[city_list].sum(axis=1) == 0)\n",
    "    # 기타 지역 인코딩: 조건에 맞는 행을 모두 1로 설정\n",
    "    df1_greencar.loc[mask, f\"기타 {region} 지역\"] = 1\n",
    "    # 나머지는 경기 여부를 0으로 설정\n",
    "    df1_greencar[f\"기타 {region} 지역\"].fillna(0, inplace=True)\n",
    "    df1_greencar[f\"기타 {region} 지역\"] = df1_greencar[f\"기타 {region} 지역\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전처리 확인\n",
    "total_count = 0\n",
    "for region in list(region_total_mapping.keys())[:-1]: #제주 제외\n",
    "    count = 0\n",
    "    print(\"\")\n",
    "    for i in region_total_mapping[f\"{region}\"][1:]: \n",
    "        print(f\"{i} :\", len(df1_greencar[df1_greencar[i]==1]))\n",
    "        count += len(df1_greencar[df1_greencar[i]==1])\n",
    "    print(\"\")\n",
    "    print(f\"{region} 총합 :\", count)\n",
    "    print(f\"{region} whole_count\", len(df1_greencar[df1_greencar[f\"{region}\"]==1]))\n",
    "    \n",
    "    total_count += len(df1_greencar[df1_greencar[f\"{region}\"]==1])\n",
    "\n",
    "for region in  list(region_total_mapping.keys())[-1:]: \n",
    "    print(f\"{region} whole_count\", len(df1_greencar[df1_greencar[f\"{region}\"]==1]))\n",
    "    total_count += len(df1_greencar[df1_greencar[f\"{region}\"]==1])\n",
    "\n",
    "print(\"total_index_count\", total_count)\n",
    "total = len(df1_greencar)\n",
    "print(\"데이터셋 전체:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4번째 열 이후의 열 선택\n",
    "columns_to_check = df1_greencar.columns[4:]\n",
    "\n",
    "# 1과 0이 아닌 값을 0으로 변경\n",
    "df1_greencar[columns_to_check] = df1_greencar[columns_to_check].where(\n",
    "    df1_greencar[columns_to_check].isin([0, 1]), 0\n",
    ").astype(int)  # int로 변환\n",
    "\n",
    "# 각 행의 합 계산\n",
    "row_sums = df1_greencar[columns_to_check].sum(axis=1)\n",
    "\n",
    "# row_sums가 0이거나 3인 행 삭제\n",
    "filtered_df1_greencar = df1_greencar[(row_sums != 0) & (row_sums != 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT_FILE = \"./key/api_key_carsharing.json\"  # 키 json 파일\n",
    "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE)\n",
    "project_id = \"carsharing-454809\"\n",
    "dataset_name = \"carsharing\"\n",
    "client = bigquery.Client(credentials=credentials, project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_gbq(df2_licenses, f\"{dataset_name}.licenses\", project_id=project_id, if_exists=\"replace\")\n",
    "print(f\"✅ BigQuery에 데이터 적재 완료: {project_id}.{dataset_name}.licenses\")\n",
    "to_gbq(filtered_df1_greencar, f\"{dataset_name}.greencars\", project_id=project_id, if_exists=\"replace\")\n",
    "print(f\"✅ BigQuery에 데이터 적재 완료: {project_id}.{dataset_name}.greencars\")\n",
    "to_gbq(df3_transport, f\"{dataset_name}.transports\", project_id=project_id, if_exists=\"replace\")\n",
    "print(f\"✅ BigQuery에 데이터 적재 완료: {project_id}.{dataset_name}.transports\")\n",
    "to_gbq(df4_poi, f\"{dataset_name}.sites\", project_id=project_id, if_exists=\"replace\")\n",
    "print(f\"✅ BigQuery에 데이터 적재 완료: {project_id}.{dataset_name}.sites\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
